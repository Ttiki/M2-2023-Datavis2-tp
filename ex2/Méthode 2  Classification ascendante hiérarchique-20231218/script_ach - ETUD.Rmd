---
title: "clustering"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```



```{r}
setwd("~/DataVis2/ex2/Méthode 2  Classification ascendante hiérarchique-20231218")
```


# Importation des données

Ce code est utilisé pour importer les données.

```{r}
library(readxl)
autos <- read_excel("autos.xls")
summary(autos)
```


# Classification hierarchique ascendante

On cherche a créer une typologie des voitures en fonction de leurs caractéristiques.

## Création de la matrice des distances

Avant de passer l'algorythme de distances, il faut : 
  - Sélectionner les variables quantitatives
  - Mettre les variables à la même échelle.
  

```{r}
# Sélectionner les variables quantitatives
autos_quant <- autos[, sapply(autos, is.numeric)]

# Mettre les variables à la même échelle
autos_scaled <- scale(autos_quant)

# Calculate the Manhattan distance matrix
dist_man <- dist(autos_scaled, method = "manhattan")
dist_euc <- dist(autos_scaled, method = "euclidean")

print(dist_man)
print(dist_euc)

```

  
Il existe de nombreuses distances mathématiques pour les variables quantitatives (euclidiennes, Manhattan). La plupart peuvent être calculées avec la fonction dist.

La distance de Gower qui peut s’appliquer à un ensemble de variables à la fois qualitatives et quantitatives et qui se calcule avec la fonction `daisy` du package {cluster}.


```{r}
library(cluster)
# Calcul de la distance de Gower
distance_gower <- daisy(autos_scaled, metric = "gower")
```

## Création des clusters

On crée les clusters avec la fonction `hclust()`. On peut choisir plusieurs méthodes pour la création des clusters, elles sont disponibles dans l'aide de la fonction hclust().

```{r}

# Création des clusters avec hclust
clust_ward <- hclust(distance_gower, method = "ward.D2")

```


## Visualisation

```{r}

# Visualisation du dendrogramme
plot(clust_ward)

```

# Calcul de l'inertie

Pour déterminer à quelle hauteur il faut découper le dendrogramme, on regarde les sauts d'inertie : 




```{r}
inertie <- sort(clust_ward$height, decreasing = TRUE)
plot(inertie[1:20], type = "s", xlab = "Nombre de classes", ylab = "Inertie")

```

il y a un saut à 2, 3 et 4 ; on représente ces partitions directement sur le dendrogramme

```{r}

# Create the dendrogram plot
plot(clust_ward)

# Découpage et coloration des clusters sur le dendrogramme
rect.hclust(clust_ward, k = 3, border = "red")
rect.hclust(clust_ward, k = 2, border = "yellow")
rect.hclust(clust_ward, k = 4, border = "blue")


```

```{r}
library(factoextra)
fviz_dend(clust_ward,k = 3, show_labels = TRUE, rect = TRUE)
```
```{r}
# Ordering the rows according to the clustering
ordered_data <- autos_scaled[order.dendrogram(as.dendrogram(clust_ward)), ]

# Creating the heatmap
heatmap(ordered_data, Rowv = as.dendrogram(clust_ward), col = heat.colors(256))

```
```{r}
# Calculate total inertia (sum of squared distances)
total_inertia <- sum(as.matrix(dist_matrix)^2)

# Function to calculate R^2 for a given number of clusters
calc_R2 <- function(k, dist_matrix) {
  clust <- hclust(dist_matrix, method = "ward.D2")
  groups <- cutree(clust, k)
  aggregate_inertia <- sum(tapply(dist_matrix, INDEX = groups, FUN = function(x) sum(x^2)))
  R2 <- (total_inertia - aggregate_inertia) / total_inertia
  return(R2)
}

# Test a range of cluster numbers and compute R^2
R2_values <- sapply(2:10, calc_R2, dist_matrix = dist_matrix)

# Find the number of clusters with the highest R^2 value
optimal_clusters <- which.max(R2_values)

print(R2_values)
print(optimal_clusters)

```


